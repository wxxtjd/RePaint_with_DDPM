{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **RePaint: Inpainting using Denoising Diffusion Probabilistic Models(CVPR 2022)**\n","### Paper: https://arxiv.org/abs/2201.09865\n","### Used Pretrained Model: https://huggingface.co/google/ddpm-celebahq-256 (by Google)\n","### Implementation Environment: Colab(GPU ~ T4)\n","\n","\n","**본 구현에서는 해당 논문의 재현을 위해 위의 사전학습된 DDPM 모델을 활용했으며, 추가적인 학습은 하지 않고 Pipeline 구조만 수정하였음.**"],"metadata":{"id":"f8nCcDC7whDq"}},{"cell_type":"markdown","source":["## Mount google"],"metadata":{"id":"iz-NlfodskZK"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZixfB0RTMHhZ","executionInfo":{"status":"ok","timestamp":1748363744878,"user_tz":-540,"elapsed":15507,"user":{"displayName":"부계","userId":"15636351040326012969"}},"outputId":"ef666ce2-8f9b-46ce-cbe9-2042452debab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Importing modules"],"metadata":{"id":"4ke8BtzGsowZ"}},{"cell_type":"code","source":["from diffusers import DDPMPipeline\n","import torch\n","from PIL import Image"],"metadata":{"id":"6rQfeaOURvoa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Jump Diffusion\n","* $x_{t}$ -> $x_{t+j}$"],"metadata":{"id":"zUSHrqNXxFVt"}},{"cell_type":"code","source":["# x_{t} -> x_{t+n}\n","def jump_diffusion(x_t, t_now, t_end, scheduler):\n","    alpha_bar_t = scheduler.alphas_cumprod[t_now]\n","    alpha_bar_next = scheduler.alphas_cumprod[t_end]\n","\n","    noise = torch.randn_like(x_t)\n","\n","    coef_1 = (alpha_bar_next / alpha_bar_t).sqrt()\n","    coef_2 = (1 - alpha_bar_next / alpha_bar_t).sqrt()\n","\n","    x_jumped = coef_1 * x_t + coef_2 * noise\n","    return x_jumped"],"metadata":{"id":"INBlm4VGRLTj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Sampling noisy x0 for conditioning\n","* $x_{0}$ -> $x_{t}$ (x0 is ground truth image)\n","\n"],"metadata":{"id":"VIgClkmtssj4"}},{"cell_type":"code","source":["# x_{0} -> x_{t}\n","def sample_conditioning(x0, t, scheduler):\n","    N, _, _, _ = x0.shape\n","    noise = torch.randn_like(x0)\n","    x_t = scheduler.add_noise(original_samples=x0, noise=noise, timesteps=(torch.ones(N, dtype=torch.long)*t).to('cuda'))\n","    return x_t"],"metadata":{"id":"1B1hhJkcTqMy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Element-wise product\n","* $m \\odot x$"],"metadata":{"id":"0OeglqfDtHNV"}},{"cell_type":"code","source":["def element_wise_product(a, x):\n","    return a*x"],"metadata":{"id":"dDXWIJKzURTD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Merge known regions with unknown regions\n","* $x_{t}$ = $(1-m) \\odot x^{unknown}_{t}$ + $m \\odot x^{known}_{t}$"],"metadata":{"id":"yxDRNB0xtnX2"}},{"cell_type":"code","source":["# x_{t-1} = (1-m)*x_{t(unknown)} + m*x_{t(known)}\n","def merge_known_unknown(x_known, x_generated, mask):\n","    x_known = element_wise_product(mask, x_known)\n","    x_unknown = element_wise_product(1-mask, x_generated)\n","    return x_known + x_unknown"],"metadata":{"id":"LzEN_lCrU1zM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Make jump time list for Resampling"],"metadata":{"id":"FPSr8BMTuetp"}},{"cell_type":"code","source":["def make_jump_t_list(max_t, j):\n","    assert max_t % j == 0, \"T must be divisible by j.\"\n","    num_steps = max_t//j+1\n","    jump_steps = [j*t-1 for t in range(num_steps)]\n","    jump_steps[0] = 0\n","    return jump_steps[::-1]"],"metadata":{"id":"lWjgTDY3X5d1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load masked image"],"metadata":{"id":"s900qAjOvUGY"}},{"cell_type":"code","source":["from PIL import Image\n","import torchvision.transforms as T\n","import torch\n","from google.colab import drive\n","\n","\n","drive.mount('/content/drive')\n","\n","# mask로 일부 가려져 손상된 이미지 경로\n","img_path = \"/content/drive/MyDrive/repaint/masked_iron.png\"\n","image = Image.open(img_path).convert(\"RGB\")\n","\n","# Transform image to tensor\n","transform = T.Compose([\n","    T.ToTensor(),\n","    T.Normalize(mean=[0.5]*3, std=[0.5]*3)  # → [-1, 1]\n","])\n","\n","x0 = transform(image).to('cuda')"],"metadata":{"id":"z9S0qDn50KAH"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FjV-cCX1L3EC"},"outputs":[],"source":["class CustomDDPMPipeline(DDPMPipeline):\n","    def custom_sample(self, mask, j, n, x0, num_inference_steps=1000, seed=42):\n","        torch.manual_seed(seed)\n","        self.scheduler.set_timesteps(num_inference_steps)\n","\n","        x_T = sample_conditioning(x0, num_inference_steps-1, self.scheduler)\n","        x = merge_known_unknown(x_T, torch.randn_like(x0), mask) # x_1000 ~ code's notation : x_999\n","\n","        jump_steps = make_jump_t_list(num_inference_steps, j)\n","\n","        # Jump cursor\n","        for cursor in range(len(jump_steps)-1):\n","            t_start = jump_steps[cursor]\n","            t_end = jump_steps[cursor+1]\n","\n","            # Repeat Resampling for n steps\n","            for resample_step in range(n):\n","\n","                # Generates unknown regions and constructs x_{t-1} by merging it with x_known\n","                for t in range(t_start, t_end, -1):\n","                    with torch.no_grad():\n","                        x_condition = sample_conditioning(x0, t-1, self.scheduler) # Get x_{t-1(known)}\n","\n","                        noise_pred = self.unet(x, t).sample\n","                        x_generated = self.scheduler.step(noise_pred, t, x).prev_sample # Get x_{t-1(unknown)}\n","\n","                        x = merge_known_unknown(x_condition, x_generated, mask) # Get x_{t-1}\n","\n","                if resample_step != n-1: # For finishing resampling\n","                    print(f\"Jumped! | t : {t_end} -> {t_start} | resample_cnt : {resample_step+1}\")\n","                    x = jump_diffusion(x, t_end, t_start, self.scheduler) # diffuse x_{t-j} to x_{t}\n","                else:\n","                    print(f\"Resampling finished. | t : {t_end} -> {t_start} | resample_cnt : {resample_step+1}\")\n","\n","        # Compuations for transforming tensor to image.\n","        images = (x / 2 + 0.5).clamp(0, 1)\n","        images = images.cpu().permute(0, 2, 3, 1).numpy()\n","        return images\n","\n","# Off-the-shelf model\n","custom_pipeline = CustomDDPMPipeline.from_pretrained(\n","    \"google/ddpm-celebahq-256\",\n","    use_safetensors=False\n",")\n","custom_pipeline = custom_pipeline.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","## 귀찮아서 아직 이 아래는 코드 정리 안해둠. 그래서 더러움. 미래의 내가 하겠지.. ##\n","sample_num = 3\n","x0 = x0.reshape(1, 3, 256, 256).repeat(sample_num, 1, 1, 1)\n","mask = torch.ones_like(x0).to('cuda')\n","mask[:, :, 50:180, 60:130] = 0 # 마스크 위치를 직접 지정하는 게 아니라 사진이랑 같이 불러오는 형식으로 수정해야 함.\n","\n","# Performing RePaint\n","imgs = custom_pipeline.custom_sample(num_inference_steps=1000, mask=mask, j=100, n=15, x0=x0) # if n=1: no resampling\n","\n","# Save results\n","for idx, img in enumerate(imgs):\n","    img = Image.fromarray((img * 255).astype(\"uint8\"))\n","    img.save(f\"/content/drive/MyDrive/result{idx}.png\")\n","    img.show()"]}]}